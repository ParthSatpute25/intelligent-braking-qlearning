# ğŸš¦ Intelligent Braking Control Using Q-Learning

This project implements a tabular Q-learning controller for an intelligent braking system in a one-dimensional (1D) vehicle simulation. The objective is to stop the vehicle precisely at a stop sign, using optimal discrete brake force actions while minimizing overshoot and stopping time. The simulation integrates vehicle dynamics using a 4th-order Runge-Kutta (RK4) solver and visualizes performance in real time using Pygame.

---

## ğŸš— Features

* âœ”ï¸ RK4-based motion integration for smooth dynamics
* ğŸ§  Q-learning agent with 128 discrete states and 5 force actions
* ğŸ” Reward shaping for precision braking behavior
* ğŸ“‰ Penalization for overshoot and insufficient deceleration
* ğŸ¥ Real-time Pygame animation and MP4 export
* ğŸ¯ Post-stop forward acceleration (500 lbf after 2s delay)
* ğŸ“Š Velocity, position, and brake force plots

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ train.py                  # Q-learning training script
â”œâ”€â”€ simulate.py               # Braking simulation and animation
â”œâ”€â”€ Q_table.npy               # Saved Q-table (auto-generated)
â”œâ”€â”€ braking_simulation.mp4    # Full animation output (auto-generated)
â””â”€â”€ README.md                 # Project overview and instructions
```

---

## âš™ï¸ How to Run

1. Install dependencies:

```bash
pip install pygame numpy matplotlib imageio imageio-ffmpeg
```

2. Train the agent:

```bash
python train.py
```

3. Run the simulation:

```bash
python simulate.py
```

After simulation ends, youâ€™ll get:

* ğŸ“¼ `braking_simulation.mp4`
* ğŸ–¼ï¸ Time-series plots of position, velocity, and force

---

## ğŸ¯ Reward Design

| Event                         | Reward  |
| ----------------------------- | ------- |
| Stopped near sign & low speed | +100    |
| Overshoot                     | -100    |
| High-speed stop near sign     | -10     |
| Passing beyond sign           | -v / 10 |
| Step cost                     | -5      |

---

## ğŸ§  Q-Learning Details

* **States**: 8 (distance) Ã— 4 (velocity) Ã— 2 (goal) Ã— 2 (mass) = 128
* **Actions**: 0, -500, -1000, -1750, -2500 lbf
* **Learning Rate**: $\alpha = 0.1$
* **Discount Factor**: $\gamma = 0.95$
* **Exploration**: Epsilon-greedy decay to 0.01
* **Episodes**: 20,000

---

## ğŸ“Š Performance Highlights

* Learns to stop accurately within 1 ft of stop sign
* Braking actions intensify as position approaches target
* Smooth transition to forward motion after 2s stop
* Full dynamics plotted and recorded

---

## ğŸ“„ License

This project is released under the MIT License.

---

## ğŸ™Œ Acknowledgments

Developed as part of **EE 5322 â€“ Intelligent Control** at the University of Texas at Arlington.
Special thanks to faculty and peers for discussions on reinforcement learning and control theory.
